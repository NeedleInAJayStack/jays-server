apiVersion: v1
kind: Pod
metadata:
  name: ollama
  labels:
    app: ollama
spec:
  containers:
  - name: ollama
    image: ollama/ollama:rocm
    ports:
    - containerPort: 11434
    env:
    - name: OLLAMA_HOST
      value: "0.0.0.0"
    - name: HSA_OVERRIDE_GFX_VERSION
      value: "10.3.0"  # TODO: Adjust based on your GPU
    - name: ROCM_PATH
      value: "/opt/rocm"
    volumeMounts:
    - name: ollama-data
      mountPath: /root/.ollama
    resources:
      requests:
        memory: "8Gi"
        amd.com/gpu: "1"
      limits:
        memory: "16Gi"
        amd.com/gpu: "1"
  volumes:
  - name: ollama-data
    hostPath:
      path: /var/lib/ollama
      type: DirectoryOrCreate
